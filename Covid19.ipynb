{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3de11907",
   "metadata": {},
   "source": [
    "## Import Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63d06a40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri Mar 13 11:54:09 2020\n",
    "\n",
    "@author: Sandi\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "# from sklearn.externals import joblib\n",
    "import joblib\n",
    "\n",
    "import pickle\n",
    "import uuid\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa7b3676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<zip object at 0x000002A99239F380>\n"
     ]
    }
   ],
   "source": [
    "descriptor = (\"d\", \"r\", \"c\")\n",
    "filenames = [r'time_series_19-covid-Deaths.csv',\n",
    "             r'time_series_19-covid-Recovered.csv',\n",
    "             r'time_series_19-covid-Confirmed.csv']\n",
    "\n",
    "print(zip(descriptor, filenames))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e16a5d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_dict = [{'hidden_layer_sizes':  [(4,4,4,4),(4,4),(4,4,3,3),(4,3,4),(10,10,10,10,10), (3,), (6,6,6,6), (4,4), (10,5,5,10), (6,), (12,12,12), (3,3,3), (6,6,6), (3,3,3,3,3), (12, 12, 6, 6, 3, 3)],\n",
    "                'activation': ['relu','identity','logistic','tanh'],\n",
    "                'solver': ['adam', 'lbfgs'],\n",
    "                'learning_rate':['constant','adaptive','invscaling'],\n",
    "                'learning_rate_init': [0.1,0.01,0.5, 0.00001],\n",
    "                'alpha': [0.01,0.1,0.001, 0.0001],\n",
    "                'max_iter': [10000]}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7aee48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on: Input Data/time_series_19-covid-Deaths.csv\n",
      "Fitting 3 folds for each of 5760 candidates, totalling 17280 fits\n"
     ]
    }
   ],
   "source": [
    "for descriptor_, fname in zip(descriptor, filenames):\n",
    "#     print(descriptor_)\n",
    "    print(\"Working on:\",'Input Data/'+ fname)\n",
    "    df = pd.read_csv('Input Data/'+ fname)\n",
    "    #print(df)\n",
    "    df.drop(columns=[\"Province/State\",\"Country/Region\"], inplace=True)\n",
    "    \n",
    "    #print(df)\n",
    "    \n",
    "    DATA = np.array((0,0,0,0))\n",
    "    \n",
    "    for i, j in df.iterrows():\n",
    "        #print(i, j)\n",
    "        latitude = j['Lat']\n",
    "        longitude = j['Long']\n",
    "        \n",
    "        for k,l in j.iteritems():\n",
    "            if k=='Lat':\n",
    "                continue\n",
    "            if k=='Long':\n",
    "                continue\n",
    "            date = datetime.strptime(k, '%m/%d/%y')\n",
    "            day = date - date.strptime(\"01/22/20\", '%m/%d/%y')\n",
    "            days = day.days\n",
    "            #print(days)\n",
    "            temp = np.array([j[\"Lat\"], j['Long'], days, l])\n",
    "            #print(temp)\n",
    "            DATA = np.vstack((DATA,temp))  \n",
    "            \n",
    "    DATA = np.delete(DATA, 0,0)\n",
    "    np.random.shuffle(DATA)\n",
    "    \n",
    "    input_data = DATA[:,:-1]\n",
    "    output_data = DATA[:, -1]\n",
    "    \n",
    "    input_train, input_test, output_train, output_test = train_test_split(input_data, output_data)\n",
    "    \n",
    "    \n",
    "    train_start_time=datetime.now()\n",
    "    clf = GridSearchCV(MLPRegressor(), params_dict, cv=3, n_jobs=-1, scoring='r2', verbose=10)\n",
    "    clf.fit(input_train, output_train)\n",
    "    train_end_time = datetime.now()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    uuid_=uuid.uuid4()\n",
    "    file = open(descriptor_+\"-\"+str(uuid_)+\"-results.txt\", 'w')\n",
    "    file.write(\"Data for: \"+fname+\"\\n\")\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "          \n",
    "          file.write(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params)+\"\\n\")\n",
    "    file.write(\"Total training time:\"+str(train_end_time-train_start_time)+\"\\n\")\n",
    "    file.close()\n",
    "    model_name = descriptor_+\"-\"+str(uuid_)+\".pickle\"\n",
    "    joblib.dump(clf.best_estimator_, model_name)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
